{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install wheel setuptools pip --upgrade\n",
        "!pip install --upgrade openai"
      ],
      "metadata": {
        "collapsed": true,
        "id": "LiKOoeBPk0NH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "!pip install optuna\n",
        "\n",
        "import pandas as pd\n",
        "import random\n",
        "from openai import OpenAI\n",
        "import time\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import re\n",
        "import nltk\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from itertools import combinations\n",
        "import optuna\n",
        "\n",
        "# Ensure the necessary NLTK resources are downloaded\n",
        "nltk.download('wordnet')\n",
        "\n",
        "API_KEY = ''\n",
        "client = OpenAI(api_key = API_KEY)\n",
        "model_id = 'gpt-3.5-turbo-0125'"
      ],
      "metadata": {
        "id": "M4xL_0vjk0P2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "from openai import OpenAI\n",
        "import time\n",
        "import numpy as np\n",
        "import gzip\n",
        "import re\n",
        "\n",
        "\n",
        "def parse(path):\n",
        "  g = gzip.open(path, 'rb')\n",
        "  for l in g:\n",
        "    yield eval(l)\n",
        "\n",
        "def getDF(path):\n",
        "  i = 0\n",
        "  df = {}\n",
        "  for d in parse(path):\n",
        "    df[i] = d\n",
        "    i += 1\n",
        "  return pd.DataFrame.from_dict(df, orient='index')\n",
        "\n",
        "# Function to truncate the string to 20 words or less\n",
        "def truncate_to_20_words(s):\n",
        "    # Check if the input is a string\n",
        "    if isinstance(s, str):\n",
        "        words = s.split()\n",
        "        return ' '.join(words[:20])\n",
        "    else:\n",
        "        # Return the input unchanged if it's not a string\n",
        "        return s\n",
        "\n",
        "Beautydf = getDF('reviews_Beauty_5.json.gz')\n",
        "Beautymetadf = getDF('meta_Beauty.json.gz')\n",
        "\n",
        "# Apply the function to the column\n",
        "Beautymetadf['title'] = Beautymetadf['title'].apply(truncate_to_20_words)\n",
        "\n",
        "merged_df = pd.merge(Beautydf, Beautymetadf, on='asin', how='left')\n",
        "merged_df = merged_df.dropna(subset=['title','description','categories','brand'])\n",
        "merged_df = merged_df.groupby('title').filter(lambda x: x['asin'].nunique() == 1)\n",
        "\n",
        "# Filter groups by size and apply the function\n",
        "merged_df6 = (merged_df.groupby('reviewerID').filter(lambda x: len(x) >= 6))  # Keep only users with >= 6 purchase history\n",
        "\n",
        "beauty_df = merged_df6.reset_index(drop = True)\n",
        "all_cand_items = list( beauty_df['title'].unique() )\n",
        "\n",
        "# use a subset for tuning\n",
        "tuning_size = 20 # change to reset tuning set\n",
        "tuning_users = beauty_df['reviewerID'].dropna().unique()[:tuning_size]\n",
        "tuning_beauty_df = beauty_df[beauty_df['reviewerID'].isin(tuning_users)]\n",
        "\n",
        "test_users = beauty_df['reviewerID'].dropna().unique()[tuning_size:]\n",
        "test_beauty_df = beauty_df[beauty_df['reviewerID'].isin(test_users)]\n"
      ],
      "metadata": {
        "id": "Z0QBgJmQk5of"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qlkdf8y8m9qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_pairwise_meteor(prompts):\n",
        "    \"\"\"\n",
        "    Compute the mean pairwise METEOR score among a list of prompts.\n",
        "\n",
        "    :param prompts: List of generated text outputs\n",
        "    :return: Mean METEOR score across all prompt pairs\n",
        "    \"\"\"\n",
        "    # Tokenize each prompt into a list of words\n",
        "    tokenized_prompts = [p.split() for p in prompts]\n",
        "\n",
        "    pairs = list(combinations(tokenized_prompts, 2))  # Get all unique pairs\n",
        "    scores = [meteor_score([p1], p2) for p1, p2 in pairs]  # Compute METEOR for each pair\n",
        "\n",
        "    return sum(scores) / len(scores) if scores else 0\n",
        "\n",
        "# # Example usage\n",
        "# prompts = [\"this is a test sentence\", \"this is an example test\", \"another test case\"]\n",
        "# mean_score = mean_pairwise_meteor(prompts)\n",
        "# print(\"Mean Pairwise METEOR Score:\", mean_score)\n",
        "\n",
        "\n",
        "\n",
        "def mean_pairwise_cosine_similarity(arrays):\n",
        "    # Stack arrays into a single matrix\n",
        "    matrix = np.vstack(arrays)\n",
        "\n",
        "    # Compute cosine similarity matrix\n",
        "    sim_matrix = cosine_similarity(matrix)\n",
        "\n",
        "    # Exclude diagonal elements (self-similarity)\n",
        "    n = len(arrays)\n",
        "    mask = np.ones((n, n), dtype=bool)\n",
        "    np.fill_diagonal(mask, 0)\n",
        "\n",
        "    # Compute the average pairwise similarity\n",
        "    avg_similarity = sim_matrix[mask].mean()\n",
        "\n",
        "    return avg_similarity\n",
        "\n",
        "# # Example usage\n",
        "# arrays = [np.random.rand(10) for _ in range(5)]  # List of 5 random 10-dimensional vectors\n",
        "# avg_sim = mean_pairwise_cosine_similarity(arrays)\n",
        "# print(\"Mean Pairwise Cosine Similarity:\", avg_sim)\n",
        "\n",
        "\n",
        "\n",
        "def ADO(num_prompts, cos_sim, lexical_sim):\n",
        "\n",
        "    for id in tuning_beauty_df['reviewerID'].unique():\n",
        "\n",
        "        user_df = tuning_beauty_df[ tuning_beauty_df['reviewerID'] == id ]\n",
        "        user_df = user_df.sort_values(by='unixReviewTime', ascending = True)\n",
        "\n",
        "        user_items = list( user_df['title'].unique() )\n",
        "\n",
        "        # keep last 15 items\n",
        "        user_items_applied = user_items[-15:]\n",
        "        break\n",
        "\n",
        "    ADO_prompt = f\"\"\"\n",
        "    We will employ GPT-3.5 to perform personalized recommendation for Beauty Products, in which we will feed GPT-3.5 with a user's prior purchase history as well as a set of candidate items to select.\n",
        "    The user's prior history consists a list of beauty products, each represented by its product title. The following can be an example for the user's prior purchase history: {user_items_applied}\n",
        "    The candidate items are a list of beauty products, each also represented by its product title.\n",
        "\n",
        "    Now, please propose a novel, detailed, and step-by-step algorithm to reformulate the user purchase history into a format that is most suitable for GPT-3.5.\n",
        "    \"\"\"\n",
        "\n",
        "    search_rounds = 3\n",
        "    prompt_performances = {}\n",
        "\n",
        "    for s in range(search_rounds):\n",
        "\n",
        "        total_try = 0\n",
        "        prompts = []\n",
        "        prompt_embeddings = []\n",
        "        prompt_cos_dict = {}\n",
        "        mean_cos_sim = 1.0\n",
        "\n",
        "        while mean_cos_sim > cos_sim:\n",
        "\n",
        "            for i in range(num_prompts):\n",
        "                completion = client.chat.completions.create(\n",
        "                    model = model_id, temperature = 1, max_tokens = 1000,\n",
        "\n",
        "                    messages=[{\"role\": \"system\", \"content\": \"Please enrich and then reformulate the user purchase history to be much more informative and detailed based on the narrative provided.\"},\n",
        "                                {\"role\": \"user\", \"content\": ADO_prompt}],\n",
        "                    timeout = 1200)\n",
        "\n",
        "                candidate_prompt = completion.choices[0].message.content\n",
        "                prompts.append(candidate_prompt)\n",
        "\n",
        "                response = client.embeddings.create(\n",
        "                    input=candidate_prompt,\n",
        "                    model=\"text-embedding-3-small\",\n",
        "                )\n",
        "\n",
        "                candidate_prompt_embedding = np.array(response.data[0].embedding)\n",
        "                prompt_embeddings.append(candidate_prompt_embedding)\n",
        "\n",
        "                # ADO_prompt += '\\n\\n\\n Please generate each step to be completely different in wording and semantics from this one: \\n\\n' + candidate_prompt + '\\n\\n\\n'\n",
        "\n",
        "\n",
        "            total_try += 1\n",
        "            mean_meteor = mean_pairwise_meteor(prompts)\n",
        "            mean_cos_sim = mean_pairwise_cosine_similarity(prompt_embeddings)\n",
        "\n",
        "            # Define min and max based on typical ranges (adjustable)\n",
        "            meteor_min, meteor_max = 0.0, 1.0  # METEOR is usually in [0,1]\n",
        "            cos_min, cos_max = 0.5, 1.0  # Cosine similarity often ranges [0.5,1] in text similarity tasks\n",
        "\n",
        "            # Min-max normalization\n",
        "            meteor_norm = (mean_meteor - meteor_min) / (meteor_max - meteor_min)\n",
        "            cos_norm = (mean_cos_sim - cos_min) / (cos_max - cos_min)\n",
        "\n",
        "            prompt_cos_dict[tuple(prompts)] = meteor_norm + cos_norm\n",
        "\n",
        "            if mean_cos_sim <= cos_sim and mean_meteor <= lexical_sim:\n",
        "                print('Qualifying prompts generated!')\n",
        "                break\n",
        "\n",
        "            if total_try > 5:\n",
        "                prompts = min(prompt_cos_dict, key=prompt_cos_dict.get)\n",
        "                break\n",
        "\n",
        "            prompts = []\n",
        "            prompt_embeddings = []\n",
        "\n",
        "\n",
        "        # Now we have the candidate prompts, start tuning set evaluation:\n",
        "        system_msg = \"Please serve as a Recommender System on Beauty Products, based on user's prior purchase information provided.\"\n",
        "\n",
        "        for candidate_prompt in prompts:\n",
        "\n",
        "            right_count = 0\n",
        "            compressed_right_count = 0\n",
        "            total = 0\n",
        "            for id in tuning_beauty_df['reviewerID'].unique():\n",
        "\n",
        "                user_df = tuning_beauty_df[ tuning_beauty_df['reviewerID'] == id ]\n",
        "                user_df = user_df.sort_values(by='unixReviewTime', ascending = True)\n",
        "\n",
        "                user_items = list( user_df['title'].unique() )\n",
        "\n",
        "                # keep last 15 items\n",
        "                user_items_applied = user_items[-15:]\n",
        "\n",
        "                # randomly generate 99 negative items (exclude all purchased items) + 1 positive item\n",
        "                filtered_list = [x for x in all_cand_items if x not in user_items]\n",
        "                sampled_items = list( random.sample(filtered_list, 99) ) # sampled items may include ground truth item (remove)\n",
        "\n",
        "                sampled_items.append( user_items_applied[-1] )\n",
        "                random.shuffle(sampled_items)\n",
        "\n",
        "                target = user_items_applied[-1]\n",
        "\n",
        "\n",
        "                augmented_prompt = (\n",
        "                        f\"Given the user has purchased the following items in chronological order: \"\n",
        "                        f\"{user_items_applied[:-1]}; output a list of 10 items to recommend out of the following candidate items ONLY; do NOT explain anything, just output the items:\"\n",
        "                        f\"\\n{sampled_items}\"\n",
        "                    )\n",
        "\n",
        "                completion = client.chat.completions.create(\n",
        "                        model = model_id, temperature = 0,\n",
        "                        messages=[{\"role\": \"system\", \"content\": system_msg},\n",
        "                                    {\"role\": \"user\", \"content\": augmented_prompt}],\n",
        "                        timeout = 1200)\n",
        "\n",
        "                pred = completion.choices[0].message.content\n",
        "\n",
        "                total += 1\n",
        "                if target in pred:\n",
        "                    right_count += 1\n",
        "\n",
        "                # Perform ADO:\n",
        "                reformulation_prompt = f'Please thoroughly reformulate the user purchase history based on the following algorithm:\\n\\n{candidate_prompt}\\n\\nUser purchase history to reformulate: {user_items_applied[:-1]}\\n\\nReturn the reformulation of the user purchase history ONLY.'\n",
        "\n",
        "                completion = client.chat.completions.create(\n",
        "                        model = model_id, temperature = 1.0,\n",
        "\n",
        "                        messages=[{\"role\": \"system\", \"content\": 'Please reformulate the user purchase history to be much more informative and detailed based on the narrative provided.'},\n",
        "                                    {\"role\": \"user\", \"content\": reformulation_prompt}],\n",
        "                        timeout = 1200)\n",
        "\n",
        "                reformulated_history = completion.choices[0].message.content\n",
        "\n",
        "\n",
        "                compressed_prompt = (\n",
        "                        f\"Given the user has purchased the following items in chronological order:\\n\\n\"\n",
        "                        f\"{reformulated_history}\\n\\nOutput a list of 10 items to recommend out of the following 100 candidate items ONLY; do NOT explain anything, just output the items:\"\n",
        "                        f\"\\n{sampled_items}\"\n",
        "                    )\n",
        "\n",
        "                completion = client.chat.completions.create(\n",
        "                        model = model_id, temperature = 0,\n",
        "                        messages=[{\"role\": \"system\", \"content\": system_msg},\n",
        "                                    {\"role\": \"user\", \"content\": compressed_prompt}],\n",
        "                        timeout = 1200)\n",
        "\n",
        "                compressed_pred = completion.choices[0].message.content\n",
        "\n",
        "                if target in compressed_pred:\n",
        "                    compressed_right_count += 1\n",
        "\n",
        "                print(right_count, compressed_right_count)\n",
        "                print()\n",
        "\n",
        "                if total % 20 == 0:\n",
        "                    print(f\"Accuracy: {right_count/total}\")\n",
        "                    print(f\"Compressed Accuracy: {compressed_right_count/total}\")\n",
        "                    print()\n",
        "\n",
        "                    if compressed_right_count <= right_count:\n",
        "                        break\n",
        "\n",
        "            prompt_performances[candidate_prompt] = compressed_right_count/total\n",
        "            print( prompt_performances[candidate_prompt] )\n",
        "\n",
        "        prior_exp = \"\"\n",
        "        for k,v in prompt_performances.items():\n",
        "            prior_exp += '\\n\\n' + 'Algorithm: ' + k + '\\n\\n' + 'Score: ' + str(v)\n",
        "\n",
        "        ADO_prompt = f\"\"\"\n",
        "        We will employ GPT-3.5 to perform personalized recommendation for Beauty Products, in which we will feed GPT-3.5 with a user's prior purchase history as well as a set of candidate items to select.\n",
        "        The user's prior history consists a list of beauty products, each represented by its product title. The following can be an example for the user's prior purchase history: {user_items_applied}\n",
        "        The candidate items are a list of beauty products, each also represented by its product title.\n",
        "\n",
        "        Now, please propose a novel, detailed, and step-by-step algorithm to reformulate the user purchase history into a format that is most suitable for GPT-3.5.\n",
        "        \"\"\"\n",
        "\n",
        "        ADO_prompt += '\\n\\nBelow are some algorithm-score pairs for you to refer to prior to generation:' + '\\n' + prior_exp\n",
        "        print(ADO_prompt)\n",
        "        print()\n",
        "\n",
        "    prompt = max(prompt_performances, key=prompt_performances.get)\n",
        "    return [prompt, prompt_performances[prompt]]\n",
        "\n",
        "\n",
        "# # example run\n",
        "# output = ADO(2, 0.7, 0.3)\n",
        "\n",
        "# print(output[0])\n",
        "# print()\n",
        "# print(output[1])\n"
      ],
      "metadata": {
        "id": "BiwCoaxInAxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rKnW1nVA4bV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# perform Bayes Opt.\n",
        "best_prompt_per_round = {}\n",
        "\n",
        "def objective(trial):\n",
        "    num_prompts = trial.suggest_int('num of prompts', 2, 4)\n",
        "    cos_sim = trial.suggest_float('Mean Cosine Sim among prompts', 0.6, 0.95, step = 0.05)\n",
        "    lexical_sim = trial.suggest_float('Mean Meteor among prompts', 0.2, 0.5, step = 0.05)\n",
        "\n",
        "    outputs = ADO(num_prompts, cos_sim, lexical_sim)\n",
        "    best_prompt_per_round[ outputs[0] ] = outputs[1]\n",
        "    print(outputs[1])\n",
        "\n",
        "    return outputs[1] # use val accuracy to search for best hyper-param set\n",
        "\n",
        "\n",
        "# start hyper-param tuning\n",
        "study = optuna.create_study(direction = 'maximize')\n",
        "study.optimize(objective, n_trials = 8)\n",
        "\n",
        "final_prompt = max(best_prompt_per_round, key=best_prompt_per_round.get)\n",
        "\n",
        "num_prompts = study.best_params['num of prompts']\n",
        "cos_sim = study.best_params['Mean Cosine Sim among prompts']\n",
        "lexical_sim = study.best_params['Mean Meteor among prompts']"
      ],
      "metadata": {
        "id": "_qJmAs-94bbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performance Evaluation"
      ],
      "metadata": {
        "id": "cCICO1IXlxF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_msg = \"Please serve as a Recommender System on Beauty Products, based on user's prior purchase information provided.\"\n",
        "\n",
        "right_count = 0\n",
        "compressed_right_count = 0\n",
        "total = 0\n",
        "for id in test_beauty_df['reviewerID'].unique():\n",
        "\n",
        "    user_df = test_beauty_df[ test_beauty_df['reviewerID'] == id ]\n",
        "    user_df = user_df.sort_values(by='unixReviewTime', ascending = True)\n",
        "\n",
        "    user_items = list( user_df['title'].unique() )\n",
        "\n",
        "    # keep last 15 items\n",
        "    user_items_applied = user_items[-15:]\n",
        "\n",
        "    # randomly generate 99 negative items (exclude all purchased items) + 1 positive item\n",
        "    filtered_list = [x for x in all_cand_items if x not in user_items]\n",
        "    sampled_items = list( random.sample(filtered_list, 99) ) # sampled items may include ground truth item (remove)\n",
        "\n",
        "    sampled_items.append( user_items_applied[-1] )\n",
        "    random.shuffle(sampled_items)\n",
        "\n",
        "    target = user_items_applied[-1]\n",
        "\n",
        "\n",
        "    augmented_prompt = (\n",
        "            f\"Given the user has purchased the following items in chronological order: \"\n",
        "            f\"{user_items_applied[:-1]}; output a list of 10 items to recommend out of the following candidate items ONLY; do NOT explain anything, just output the items:\"\n",
        "            f\"\\n{sampled_items}\"\n",
        "        )\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "            model = model_id, temperature = 0,\n",
        "            messages=[{\"role\": \"system\", \"content\": system_msg},\n",
        "                        {\"role\": \"user\", \"content\": augmented_prompt}],\n",
        "            timeout = 1200)\n",
        "\n",
        "    pred = completion.choices[0].message.content\n",
        "\n",
        "    total += 1\n",
        "    if target in pred:\n",
        "        right_count += 1\n",
        "\n",
        "    # Perform ADO:\n",
        "    reformulation_prompt = f'Please thoroughly reformulate the user purchase history based on the following algorithm:\\n\\n{final_prompt}\\n\\nUser purchase history to reformulate: {user_items_applied[:-1]}\\n\\nReturn the reformulation of the user purchase history ONLY.'\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "            model = model_id, temperature = 1.0,\n",
        "\n",
        "            messages=[{\"role\": \"system\", \"content\": 'Please reformulate the user purchase history to be much more informative and detailed based on the narrative provided.'},\n",
        "                        {\"role\": \"user\", \"content\": reformulation_prompt}],\n",
        "            timeout = 1200)\n",
        "\n",
        "    reformulated_history = completion.choices[0].message.content\n",
        "\n",
        "\n",
        "    compressed_prompt = (\n",
        "            f\"Given the user has purchased the following items in chronological order:\\n\\n\"\n",
        "            f\"{reformulated_history}\\n\\nOutput a list of 10 items to recommend out of the following 100 candidate items ONLY; do NOT explain anything, just output the items:\"\n",
        "            f\"\\n{sampled_items}\"\n",
        "        )\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "            model = model_id, temperature = 0,\n",
        "            messages=[{\"role\": \"system\", \"content\": system_msg},\n",
        "                        {\"role\": \"user\", \"content\": compressed_prompt}],\n",
        "            timeout = 1200)\n",
        "\n",
        "    compressed_pred = completion.choices[0].message.content\n",
        "\n",
        "    if target in compressed_pred:\n",
        "        compressed_right_count += 1\n",
        "\n",
        "    print(right_count, compressed_right_count)\n",
        "    print()\n",
        "\n",
        "    if total % 20 == 0:\n",
        "        print(f\"Accuracy: {right_count/total}\")\n",
        "        print(f\"Compressed Accuracy: {compressed_right_count/total}\")\n",
        "        print()"
      ],
      "metadata": {
        "id": "h5QvweS-hk-5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}