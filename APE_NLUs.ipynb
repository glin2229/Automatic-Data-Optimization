{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbtllx-HG0Xf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 937
        },
        "collapsed": true,
        "outputId": "e45e1090-240e-4ad7-a629-c717d651f342"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (0.44.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (71.0.4)\n",
            "Collecting setuptools\n",
            "  Using cached setuptools-75.1.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB)\n",
            "Using cached setuptools-75.1.0-py3-none-any.whl (1.2 MB)\n",
            "Using cached pip-24.2-py3-none-any.whl (1.8 MB)\n",
            "Installing collected packages: setuptools, pip\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 71.0.4\n",
            "    Uninstalling setuptools-71.0.4:\n",
            "      Successfully uninstalled setuptools-71.0.4\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pip-24.2 setuptools-75.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "pkg_resources",
                  "setuptools"
                ]
              },
              "id": "2d833c87fa1a4e03b60e159916125487"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.51.2-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Downloading openai-1.51.2-py3-none-any.whl (383 kB)\n",
            "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "Downloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "Downloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "Installing collected packages: jiter, h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jiter-0.6.1 openai-1.51.2\n"
          ]
        }
      ],
      "source": [
        "!pip install wheel setuptools pip --upgrade\n",
        "!pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import random\n",
        "from openai import OpenAI\n",
        "import time\n",
        "import numpy as np\n",
        "import gzip\n",
        "import re\n",
        "\n",
        "API_KEY = ''\n",
        "client = OpenAI(api_key = API_KEY)\n",
        "model_id = 'gpt-3.5-turbo-0125' #gpt-3.5-turbo-0125, gpt-4-turbo-2024-04-09\n",
        "\n",
        "# Replace 'path_to_file.jsonl' with the path to your JSONL file\n",
        "file_path = 'GSM8K.jsonl'\n",
        "\n",
        "data = []\n",
        "\n",
        "# Open the file and read each line\n",
        "with open(file_path, 'r') as file:\n",
        "    for line in file:\n",
        "        # Convert each JSON string into a Python dictionary\n",
        "        json_dict = json.loads(line)\n",
        "        data.append(json_dict)\n",
        "\n",
        "# 'data' is now a list of dictionaries\n",
        "print(data[11]['question'])\n",
        "print( re.findall(r'\\n#### (.*)', data[11]['answer'])[0] )\n",
        "\n",
        "samples = []\n",
        "targets = []\n",
        "for i in range(10):\n",
        "    samples.append(data[i]['question'])\n",
        "    targets.append( re.findall(r'\\n#### (.*)', data[i]['answer'])[0] )\n"
      ],
      "metadata": {
        "id": "OvbEQv37G24k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meta_prompt = f\"\"\"\n",
        "You are given a math question statement. Your task is to propose a creative, detailed, and step-by-step algorithm to reformulate and enrich this question statement. The goal is of the algorithm is to perform a thorough engineering on the statement, so that it is easier for a LLM to solve it. Below are some sample math question statements as refrences.\n",
        "\n",
        "Examples:\n",
        "- Job Description: '{samples[0]}'; Is the job Fraud or not: '{targets[0]}'\n",
        "- Job Description: '{samples[1]}'; Is the job Fraud or not: '{targets[1]}'\n",
        "- Job Description: '{samples[2]}'; Is the job Fraud or not: '{targets[2]}'\n",
        "- Job Description: '{samples[3]}'; Is the job Fraud or not: '{targets[3]}'\n",
        "- Job Description: '{samples[4]}'; Is the job Fraud or not: '{targets[4]}'\n",
        "- Job Description: '{samples[5]}'; Is the job Fraud or not: '{targets[5]}'\n",
        "- Job Description: '{samples[6]}'; Is the job Fraud or not: '{targets[6]}'\n",
        "- Job Description: '{samples[7]}'; Is the job Fraud or not: '{targets[7]}'\n",
        "- Job Description: '{samples[8]}'; Is the job Fraud or not: '{targets[8]}'\n",
        "- Job Description: '{samples[9]}'; Is the job Fraud or not: '{targets[9]}'\n",
        "\n",
        "For each step of the algorithm, number and then start it on a new line; you must start each step with '###------- Step 1: ' The proposed algorithm will later be submitted to a LLM for processing.\n",
        "Important: Do NOT refer to any external database; Do NOT perform the item counting. Do NOT perform normalization. Do NOT perform vector generations. Do NOT propose to draw anything. Do NOT perform similarity checking. Do NOT propose how to train or generate a recommendation system. ONLY propose steps that a LLM can generate on its own!!!\n",
        "\"\"\"\n",
        "\n",
        "prompts = []\n",
        "prompt_performances = {}\n",
        "for i in range(7):\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "        model = model_id, temperature = 1.0,\n",
        "\n",
        "        messages=[{\"role\": \"system\", \"content\": \"Please come up with a step-by-step, very detailed, clear, and novel algorithm for reformulating and enriching a math question statement for easier LLM processing. Return the steps ONLY!!! NO more than 5 steps. You MUST NOT propose to directly answer the question in the steps!!!\"},\n",
        "                    {\"role\": \"user\", \"content\": meta_prompt}],\n",
        "        timeout = 1200)\n",
        "\n",
        "    candidate_prompt = completion.choices[0].message.content\n",
        "    prompts.append(candidate_prompt)\n",
        "    print(candidate_prompt)\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "ZbbMCKAGHSAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "for candidate_prompt in prompts:\n",
        "\n",
        "    print(candidate_prompt)\n",
        "    print()\n",
        "\n",
        "    # Regular expression to split the text into individual algorithms\n",
        "    algorithm_pattern = r\"###------- Step \\d: [\\w\\s]+\"\n",
        "\n",
        "    # Split the text based on the pattern\n",
        "    split_text = re.split(algorithm_pattern, candidate_prompt)\n",
        "\n",
        "    # Extract the algorithm headers (for identification)\n",
        "    headers = re.findall(algorithm_pattern, candidate_prompt)\n",
        "\n",
        "    # Removing the first empty string from the split if exists (because of the split at the start)\n",
        "    split_text = [t.strip() for t in split_text if t.strip()]\n",
        "\n",
        "    # Create a dictionary where each algorithm is stored separately\n",
        "    algorithms = {headers[i]: split_text[i] for i in range(len(headers))}\n",
        "\n",
        "    # Display each algorithm separately\n",
        "    steps = []\n",
        "    for header, content in algorithms.items():\n",
        "        steps.append( [header, content] )\n",
        "        # print(f\"{header}:\\n{content}\\n\")\n",
        "\n",
        "    total_right = 0\n",
        "    ADE_total_right = 0\n",
        "    total = 0\n",
        "\n",
        "    for i in range(11, len(data)):\n",
        "        question = data[i]['question']\n",
        "        target = re.findall(r'\\n#### (.*)', data[i]['answer'])[0]\n",
        "\n",
        "        original_prompt = (\n",
        "            'Given a math question, please solve it by returning the final answer as a number.' +\n",
        "            f'\\n\\nQuestion: {question}' +\n",
        "            \"Output format: directly return an algebric number representing the answer; do NOT explain anything. You MUST follow this format: 'The answer is: 34.5'!!!\"\n",
        "        )\n",
        "\n",
        "        completion = client.chat.completions.create(\n",
        "            model = model_id, temperature = 0, seed = 0,\n",
        "\n",
        "            messages=[{\"role\": \"system\", \"content\": 'Please solve the math question presented by outputting the final answer.'},\n",
        "                        {\"role\": \"user\", \"content\": original_prompt}],\n",
        "            timeout = 1200)\n",
        "\n",
        "        ori_answer = completion.choices[0].message.content\n",
        "\n",
        "        total += 1\n",
        "        match = re.search(r'[-+]?\\d*\\.\\d+|\\d+', ori_answer)\n",
        "        if match:\n",
        "            ori_answer = float(match.group())\n",
        "\n",
        "        if float(target) == float(ori_answer):\n",
        "            total_right += 1\n",
        "\n",
        "\n",
        "        overall_with_steps = \"Original question statement: \" + question + '\\n\\n'\n",
        "        for i in range(len(algorithms)):\n",
        "\n",
        "            reformulation_prompt = f\"Please thoroughly reformulate the math question statement based on the following instruction:\\n\\n{steps[i][0]}\\n{steps[i][1]}\\n\\nQuestion statement to reformulate: {overall_with_steps}.\"\n",
        "\n",
        "            completion = client.chat.completions.create(\n",
        "                    model = model_id, temperature = 0.0, max_tokens = 768,\n",
        "\n",
        "                    messages=[{\"role\": \"system\", \"content\": \"Please reformulate and enrich the math question to be extremely informative and detailed for LLM to interpret better. You are allowed to infer and fill-in unspecified information based on your domain expertise!\"},\n",
        "                                {\"role\": \"user\", \"content\": reformulation_prompt}],\n",
        "                    timeout = 1200)\n",
        "\n",
        "            reformulated_history = completion.choices[0].message.content\n",
        "            # print('Step ' + str(i) + ' Results: ')\n",
        "            # print(reformulated_history)\n",
        "            overall_with_steps += steps[i][0] + '\\n' + steps[i][1] + reformulated_history + '\\n\\n'\n",
        "            # print()\n",
        "            # print()\n",
        "\n",
        "        print(overall_with_steps)\n",
        "        print()\n",
        "\n",
        "        ADE_prompt = (\n",
        "            'Given a math question, please solve it by returning the final answer as a number.' +\n",
        "            f'\\n\\nQuestion: {overall_with_steps}' +\n",
        "            \"Output format: directly return an algebric number representing the answer; do NOT explain anything. You MUST follow this format: 'The answer is: 34.5'!!!\"\n",
        "        )\n",
        "\n",
        "        completion = client.chat.completions.create(\n",
        "            model = model_id, temperature = 0, seed = 0,\n",
        "\n",
        "            messages=[{\"role\": \"system\", \"content\": 'Please solve the math question presented by outputting the final answer.'},\n",
        "                        {\"role\": \"user\", \"content\": ADE_prompt}],\n",
        "            timeout = 1200)\n",
        "\n",
        "        answer = completion.choices[0].message.content\n",
        "\n",
        "        match = re.search(r'[-+]?\\d*\\.\\d+|\\d+', answer)\n",
        "        if match:\n",
        "            answer = float(match.group())\n",
        "\n",
        "        if float(target) == float(answer):\n",
        "            ADE_total_right += 1\n",
        "\n",
        "        print(target, ori_answer, answer)\n",
        "        print(f'Total: {total}, Total Right: {total_right}, ADE Total Right: {ADE_total_right}')\n",
        "        print('----------------------------------------------------------------------------------------')\n",
        "        print()\n",
        "\n",
        "        if total % 50 == 0:\n",
        "            if total_right >= ADE_total_right:\n",
        "                prompt_performances[candidate_prompt] = ADE_total_right / total\n",
        "                print()\n",
        "                break\n",
        "\n",
        "        if total >= 200:\n",
        "            prompt_performances[candidate_prompt] = ADE_total_right / total\n",
        "            break\n"
      ],
      "metadata": {
        "id": "F3xJ4Qj5HSPd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}