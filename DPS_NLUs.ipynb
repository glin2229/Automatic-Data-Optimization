{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install wheel setuptools pip --upgrade\n",
        "!pip install --upgrade openai"
      ],
      "metadata": {
        "collapsed": true,
        "id": "DtVquvUjACY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "!pip install optuna\n",
        "\n",
        "import pandas as pd\n",
        "import random\n",
        "from openai import OpenAI\n",
        "import time\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import re\n",
        "import nltk\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from itertools import combinations\n",
        "import optuna\n",
        "import json\n",
        "import gzip\n",
        "\n",
        "# Ensure the necessary NLTK resources are downloaded\n",
        "nltk.download('wordnet')\n",
        "\n",
        "API_KEY = ''\n",
        "client = OpenAI(api_key = API_KEY)\n",
        "model_id = 'gpt-3.5-turbo-0125'"
      ],
      "metadata": {
        "id": "AGMYacHTAWFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace 'path_to_file.jsonl' with the path to your JSONL file\n",
        "file_path = 'GSM8K.jsonl'\n",
        "\n",
        "data = []\n",
        "\n",
        "# Open the file and read each line\n",
        "with open(file_path, 'r') as file:\n",
        "    for line in file:\n",
        "        # Convert each JSON string into a Python dictionary\n",
        "        json_dict = json.loads(line)\n",
        "        data.append(json_dict)\n",
        "\n",
        "# 'data' is now a list of dictionaries\n",
        "print(data[11]['question'])\n",
        "print( re.findall(r'\\n#### (.*)', data[11]['answer'])[0] )\n"
      ],
      "metadata": {
        "id": "Y5OcJDrgAFJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_pairwise_meteor(prompts):\n",
        "    \"\"\"\n",
        "    Compute the mean pairwise METEOR score among a list of prompts.\n",
        "\n",
        "    :param prompts: List of generated text outputs\n",
        "    :return: Mean METEOR score across all prompt pairs\n",
        "    \"\"\"\n",
        "    # Tokenize each prompt into a list of words\n",
        "    tokenized_prompts = [p.split() for p in prompts]\n",
        "\n",
        "    pairs = list(combinations(tokenized_prompts, 2))  # Get all unique pairs\n",
        "    scores = [meteor_score([p1], p2) for p1, p2 in pairs]  # Compute METEOR for each pair\n",
        "\n",
        "    return sum(scores) / len(scores) if scores else 0\n",
        "\n",
        "# # Example usage\n",
        "# prompts = [\"this is a test sentence\", \"this is an example test\", \"another test case\"]\n",
        "# mean_score = mean_pairwise_meteor(prompts)\n",
        "# print(\"Mean Pairwise METEOR Score:\", mean_score)\n",
        "\n",
        "\n",
        "\n",
        "def mean_pairwise_cosine_similarity(arrays):\n",
        "    # Stack arrays into a single matrix\n",
        "    matrix = np.vstack(arrays)\n",
        "\n",
        "    # Compute cosine similarity matrix\n",
        "    sim_matrix = cosine_similarity(matrix)\n",
        "\n",
        "    # Exclude diagonal elements (self-similarity)\n",
        "    n = len(arrays)\n",
        "    mask = np.ones((n, n), dtype=bool)\n",
        "    np.fill_diagonal(mask, 0)\n",
        "\n",
        "    # Compute the average pairwise similarity\n",
        "    avg_similarity = sim_matrix[mask].mean()\n",
        "\n",
        "    return avg_similarity\n",
        "\n",
        "# # Example usage\n",
        "# arrays = [np.random.rand(10) for _ in range(5)]  # List of 5 random 10-dimensional vectors\n",
        "# avg_sim = mean_pairwise_cosine_similarity(arrays)\n",
        "# print(\"Mean Pairwise Cosine Similarity:\", avg_sim)\n",
        "\n",
        "\n",
        "\n",
        "def ADO(num_prompts, cos_sim, lexical_sim):\n",
        "\n",
        "    samples = []\n",
        "    targets = []\n",
        "    for i in range(10):\n",
        "        samples.append(data[i]['question'])\n",
        "        targets.append( re.findall(r'\\n#### (.*)', data[i]['answer'])[0] )\n",
        "\n",
        "    ADO_prompt = f\"\"\"\n",
        "    You are given a math question statement. Your task is to propose a creative, detailed, and step-by-step algorithm to reformulate and enrich this question statement. The goal is of the algorithm is to perform a thorough engineering on the statement, so that it is easier for a LLM to solve it. Below are some sample math question statements as refrences.\n",
        "\n",
        "    Examples:\n",
        "    - Job Description: '{samples[0]}'; Is the job Fraud or not: '{targets[0]}'\n",
        "    - Job Description: '{samples[1]}'; Is the job Fraud or not: '{targets[1]}'\n",
        "    - Job Description: '{samples[2]}'; Is the job Fraud or not: '{targets[2]}'\n",
        "    - Job Description: '{samples[3]}'; Is the job Fraud or not: '{targets[3]}'\n",
        "    - Job Description: '{samples[4]}'; Is the job Fraud or not: '{targets[4]}'\n",
        "    - Job Description: '{samples[5]}'; Is the job Fraud or not: '{targets[5]}'\n",
        "    - Job Description: '{samples[6]}'; Is the job Fraud or not: '{targets[6]}'\n",
        "    - Job Description: '{samples[7]}'; Is the job Fraud or not: '{targets[7]}'\n",
        "    - Job Description: '{samples[8]}'; Is the job Fraud or not: '{targets[8]}'\n",
        "    - Job Description: '{samples[9]}'; Is the job Fraud or not: '{targets[9]}'\n",
        "\n",
        "    Important: You MUST NOT solve the samples above! The samples are only to get you familiar to the statements you will enrich and reformulate.\n",
        "\n",
        "    For each step of the algorithm, number and then start it on a new line; you must start each step with '###------- Step 1: ' The proposed algorithm will later be submitted to a LLM for processing.\n",
        "    Important: Do NOT refer to any external database; Do NOT perform the item counting. Do NOT perform normalization. Do NOT perform vector generations. Do NOT propose to draw anything. Do NOT perform similarity checking. Do NOT propose how to train or generate a recommendation system. ONLY propose steps that a LLM can generate on its own!!!\n",
        "    \"\"\"\n",
        "\n",
        "    search_rounds = 3\n",
        "    tuning_size = 10\n",
        "    prompt_performances = {}\n",
        "\n",
        "    for s in range(search_rounds):\n",
        "\n",
        "        total_try = 0\n",
        "        prompts = []\n",
        "        prompt_embeddings = []\n",
        "        prompt_cos_dict = {}\n",
        "        mean_cos_sim = 1.0\n",
        "\n",
        "        while mean_cos_sim > cos_sim:\n",
        "\n",
        "            for i in range(num_prompts):\n",
        "                completion = client.chat.completions.create(\n",
        "                    model = model_id, temperature = 1, max_tokens = 1000,\n",
        "\n",
        "                    messages=[{\"role\": \"system\", \"content\": \"Please reformulate and enrich the math question to be extremely informative and detailed for LLM to interpret better. You are allowed to infer and fill-in unspecified information based on your domain expertise!\"},\n",
        "                                {\"role\": \"user\", \"content\": ADO_prompt}],\n",
        "                    timeout = 1200)\n",
        "\n",
        "                candidate_prompt = completion.choices[0].message.content\n",
        "                prompts.append(candidate_prompt)\n",
        "\n",
        "                response = client.embeddings.create(\n",
        "                    input=candidate_prompt,\n",
        "                    model=\"text-embedding-3-small\",\n",
        "                )\n",
        "\n",
        "                candidate_prompt_embedding = np.array(response.data[0].embedding)\n",
        "                prompt_embeddings.append(candidate_prompt_embedding)\n",
        "\n",
        "                # ADO_prompt += '\\n\\n\\n Please generate each step to be completely different in wording and semantics from this one: \\n\\n' + candidate_prompt + '\\n\\n\\n'\n",
        "\n",
        "\n",
        "            total_try += 1\n",
        "            mean_meteor = mean_pairwise_meteor(prompts)\n",
        "            mean_cos_sim = mean_pairwise_cosine_similarity(prompt_embeddings)\n",
        "\n",
        "            # Define min and max based on typical ranges (adjustable)\n",
        "            meteor_min, meteor_max = 0.0, 1.0  # METEOR is usually in [0,1]\n",
        "            cos_min, cos_max = 0.5, 1.0  # Cosine similarity often ranges [0.5,1] in text similarity tasks\n",
        "\n",
        "            # Min-max normalization\n",
        "            meteor_norm = (mean_meteor - meteor_min) / (meteor_max - meteor_min)\n",
        "            cos_norm = (mean_cos_sim - cos_min) / (cos_max - cos_min)\n",
        "\n",
        "            prompt_cos_dict[tuple(prompts)] = meteor_norm + cos_norm\n",
        "\n",
        "            if mean_cos_sim <= cos_sim and mean_meteor <= lexical_sim:\n",
        "                print('Qualifying prompts generated!')\n",
        "                break\n",
        "\n",
        "            if total_try > 5:\n",
        "                prompts = min(prompt_cos_dict, key=prompt_cos_dict.get)\n",
        "                break\n",
        "\n",
        "            prompts = []\n",
        "            prompt_embeddings = []\n",
        "\n",
        "\n",
        "        # Now we have the candidate prompts, start tuning set evaluation:\n",
        "        for candidate_prompt in prompts:\n",
        "\n",
        "            print(candidate_prompt)\n",
        "            print()\n",
        "\n",
        "            # Regular expression to split the text into individual algorithms\n",
        "            algorithm_pattern = r\"###------- Step \\d: [\\w\\s]+\"\n",
        "\n",
        "            # Split the text based on the pattern\n",
        "            split_text = re.split(algorithm_pattern, candidate_prompt)\n",
        "\n",
        "            # Extract the algorithm headers (for identification)\n",
        "            headers = re.findall(algorithm_pattern, candidate_prompt)\n",
        "\n",
        "            # Removing the first empty string from the split if exists (because of the split at the start)\n",
        "            split_text = [t.strip() for t in split_text if t.strip()]\n",
        "\n",
        "            # Create a dictionary where each algorithm is stored separately\n",
        "            algorithms = {headers[i]: split_text[i] for i in range(len(headers))}\n",
        "\n",
        "            # Display each algorithm separately\n",
        "            steps = []\n",
        "            for header, content in algorithms.items():\n",
        "                steps.append( [header, content] )\n",
        "                # print(f\"{header}:\\n{content}\\n\")\n",
        "\n",
        "            total_right = 0\n",
        "            ADO_total_right = 0\n",
        "            total = 0\n",
        "\n",
        "            for i in range( len(data) ):\n",
        "                question = data[i]['question']\n",
        "                target = re.findall(r'\\n#### (.*)', data[i]['answer'])[0]\n",
        "\n",
        "                original_prompt = (\n",
        "                    'Given a math question, please solve it by returning the final answer as a number.' +\n",
        "                    f'\\n\\nQuestion: {question}' +\n",
        "                    \"Output format: directly return an algebric number representing the answer; do NOT explain anything. You MUST follow this format: 'The answer is: 34.5'!!!\"\n",
        "                )\n",
        "\n",
        "                completion = client.chat.completions.create(\n",
        "                    model = model_id, temperature = 0, seed = 0,\n",
        "\n",
        "                    messages=[{\"role\": \"system\", \"content\": 'Please solve the math question presented by outputting the final answer.'},\n",
        "                                {\"role\": \"user\", \"content\": original_prompt}],\n",
        "                    timeout = 1200)\n",
        "\n",
        "                ori_answer = completion.choices[0].message.content\n",
        "\n",
        "                total += 1\n",
        "                match = re.search(r'[-+]?\\d*\\.\\d+|\\d+', ori_answer)\n",
        "                if match:\n",
        "                    ori_answer = float(match.group())\n",
        "\n",
        "                if float(target) == float(ori_answer):\n",
        "                    total_right += 1\n",
        "\n",
        "\n",
        "                overall_with_steps = \"Original question statement: \" + question + '\\n\\n'\n",
        "                for i in range(len(algorithms)):\n",
        "\n",
        "                    reformulation_prompt = f\"Please thoroughly reformulate the math question statement based on the following instruction:\\n\\n{steps[i][0]}\\n{steps[i][1]}\\n\\nQuestion statement to reformulate: {overall_with_steps}.\"\n",
        "\n",
        "                    completion = client.chat.completions.create(\n",
        "                            model = model_id, temperature = 0.0, max_tokens = 768,\n",
        "\n",
        "                            messages=[{\"role\": \"system\", \"content\": \"Please reformulate and enrich the math question to be extremely informative and detailed for LLM to interpret better. You are allowed to infer and fill-in unspecified information based on your domain expertise!\"},\n",
        "                                        {\"role\": \"user\", \"content\": reformulation_prompt}],\n",
        "                            timeout = 1200)\n",
        "\n",
        "                    reformulated_history = completion.choices[0].message.content\n",
        "                    overall_with_steps += steps[i][0] + '\\n' + steps[i][1] + reformulated_history + '\\n\\n'\n",
        "\n",
        "                ADO_prompt = (\n",
        "                    'Given a math question, please solve it by returning the final answer as a number.' +\n",
        "                    f'\\n\\nQuestion: {overall_with_steps}' +\n",
        "                    \"Output format: directly return an algebric number representing the answer; do NOT explain anything. You MUST follow this format: 'The answer is: 34.5'!!!\"\n",
        "                )\n",
        "\n",
        "                completion = client.chat.completions.create(\n",
        "                    model = model_id, temperature = 0, seed = 0,\n",
        "\n",
        "                    messages=[{\"role\": \"system\", \"content\": 'Please solve the math question presented by outputting the final answer.'},\n",
        "                                {\"role\": \"user\", \"content\": ADO_prompt}],\n",
        "                    timeout = 1200)\n",
        "\n",
        "                answer = completion.choices[0].message.content\n",
        "\n",
        "                match = re.search(r'[-+]?\\d*\\.\\d+|\\d+', answer)\n",
        "                if match:\n",
        "                    answer = float(match.group())\n",
        "\n",
        "                if float(target) == float(answer):\n",
        "                    ADO_total_right += 1\n",
        "\n",
        "                print(target, ori_answer, answer)\n",
        "                print(f'Total: {total}, Total Right: {total_right}, ADE Total Right: {ADO_total_right}')\n",
        "                print('----------------------------------------------------------------------------------------')\n",
        "                print()\n",
        "\n",
        "                if total % 50 == 0:\n",
        "                    if total_right >= ADO_total_right:\n",
        "                        break\n",
        "\n",
        "                if total >= tuning_size:\n",
        "                    break\n",
        "\n",
        "            prompt_performances[candidate_prompt] = ADO_total_right/total\n",
        "            print( prompt_performances[candidate_prompt] )\n",
        "\n",
        "        prior_exp = \"\"\n",
        "        for k,v in prompt_performances.items():\n",
        "            prior_exp += '\\n\\n' + 'Algorithm: ' + k + '\\n\\n' + 'Score: ' + str(v)\n",
        "\n",
        "        ADO_prompt = f\"\"\"\n",
        "        You are given a math question statement. Your task is to propose a creative, detailed, and step-by-step algorithm to reformulate and enrich this question statement. The goal is of the algorithm is to perform a thorough engineering on the statement, so that it is easier for a LLM to solve it. Below are some sample math question statements as refrences.\n",
        "\n",
        "        Examples:\n",
        "        - Job Description: '{samples[0]}'; Is the job Fraud or not: '{targets[0]}'\n",
        "        - Job Description: '{samples[1]}'; Is the job Fraud or not: '{targets[1]}'\n",
        "        - Job Description: '{samples[2]}'; Is the job Fraud or not: '{targets[2]}'\n",
        "        - Job Description: '{samples[3]}'; Is the job Fraud or not: '{targets[3]}'\n",
        "        - Job Description: '{samples[4]}'; Is the job Fraud or not: '{targets[4]}'\n",
        "        - Job Description: '{samples[5]}'; Is the job Fraud or not: '{targets[5]}'\n",
        "        - Job Description: '{samples[6]}'; Is the job Fraud or not: '{targets[6]}'\n",
        "        - Job Description: '{samples[7]}'; Is the job Fraud or not: '{targets[7]}'\n",
        "        - Job Description: '{samples[8]}'; Is the job Fraud or not: '{targets[8]}'\n",
        "        - Job Description: '{samples[9]}'; Is the job Fraud or not: '{targets[9]}'\n",
        "\n",
        "        Important: You MUST NOT solve the samples above! The samples are only to get you familiar to the statements you will enrich and reformulate.\n",
        "\n",
        "        For each step of the algorithm, number and then start it on a new line; you must start each step with '###------- Step 1: ' The proposed algorithm will later be submitted to a LLM for processing.\n",
        "        Important: Do NOT refer to any external database; Do NOT perform the item counting. Do NOT perform normalization. Do NOT perform vector generations. Do NOT propose to draw anything. Do NOT perform similarity checking. Do NOT propose how to train or generate a recommendation system. ONLY propose steps that a LLM can generate on its own!!!\n",
        "        \"\"\"\n",
        "\n",
        "        ADO_prompt += '\\n\\nBelow are some algorithm-score pairs for you to refer to prior to generation:' + '\\n' + prior_exp\n",
        "        print(ADO_prompt)\n",
        "        print()\n",
        "\n",
        "    prompt = max(prompt_performances, key=prompt_performances.get)\n",
        "    return [prompt, prompt_performances[prompt]]\n",
        "\n",
        "\n",
        "# # example run\n",
        "# output = ADO(2, 0.7, 0.3)\n",
        "\n",
        "# print(output[0])\n",
        "# print()\n",
        "# print(output[1])"
      ],
      "metadata": {
        "id": "luQd67AhAlNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CFWJfG1vESDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# perform Bayes Opt.\n",
        "best_prompt_per_round = {}\n",
        "\n",
        "def objective(trial):\n",
        "    num_prompts = trial.suggest_int('num of prompts', 2, 4)\n",
        "    cos_sim = trial.suggest_float('Mean Cosine Sim among prompts', 0.6, 0.95, step = 0.05)\n",
        "    lexical_sim = trial.suggest_float('Mean Meteor among prompts', 0.2, 0.5, step = 0.05)\n",
        "\n",
        "    outputs = ADO(num_prompts, cos_sim, lexical_sim)\n",
        "    best_prompt_per_round[ outputs[0] ] = outputs[1]\n",
        "    print(outputs[1])\n",
        "\n",
        "    return outputs[1] # use val accuracy to search for best hyper-param set\n",
        "\n",
        "\n",
        "# start hyper-param tuning\n",
        "study = optuna.create_study(direction = 'maximize')\n",
        "study.optimize(objective, n_trials = 8)\n",
        "\n",
        "final_prompt = max(best_prompt_per_round, key=best_prompt_per_round.get)\n",
        "\n",
        "num_prompts = study.best_params['num of prompts']\n",
        "cos_sim = study.best_params['Mean Cosine Sim among prompts']\n",
        "lexical_sim = study.best_params['Mean Meteor among prompts']"
      ],
      "metadata": {
        "id": "OmS0C0j7ESnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performance Evaluation"
      ],
      "metadata": {
        "id": "A_dJo1aElQHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuning_size = 200\n",
        "\n",
        "print(final_prompt)\n",
        "print()\n",
        "\n",
        "# Regular expression to split the text into individual algorithms\n",
        "algorithm_pattern = r\"###------- Step \\d: [\\w\\s]+\"\n",
        "\n",
        "# Split the text based on the pattern\n",
        "split_text = re.split(algorithm_pattern, final_prompt)\n",
        "\n",
        "# Extract the algorithm headers (for identification)\n",
        "headers = re.findall(algorithm_pattern, final_prompt)\n",
        "\n",
        "# Removing the first empty string from the split if exists (because of the split at the start)\n",
        "split_text = [t.strip() for t in split_text if t.strip()]\n",
        "\n",
        "# Create a dictionary where each algorithm is stored separately\n",
        "algorithms = {headers[i]: split_text[i] for i in range(len(headers))}\n",
        "\n",
        "# Display each algorithm separately\n",
        "steps = []\n",
        "for header, content in algorithms.items():\n",
        "    steps.append( [header, content] )\n",
        "    # print(f\"{header}:\\n{content}\\n\")\n",
        "\n",
        "total_right = 0\n",
        "ADO_total_right = 0\n",
        "total = 0\n",
        "\n",
        "for i in range( tuning_size, len(data) ):\n",
        "    question = data[i]['question']\n",
        "    target = re.findall(r'\\n#### (.*)', data[i]['answer'])[0]\n",
        "\n",
        "    original_prompt = (\n",
        "        'Given a math question, please solve it by returning the final answer as a number.' +\n",
        "        f'\\n\\nQuestion: {question}' +\n",
        "        \"Output format: directly return an algebric number representing the answer; do NOT explain anything. You MUST follow this format: 'The answer is: 34.5'!!!\"\n",
        "    )\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "        model = model_id, temperature = 0, seed = 0,\n",
        "\n",
        "        messages=[{\"role\": \"system\", \"content\": 'Please solve the math question presented by outputting the final answer.'},\n",
        "                    {\"role\": \"user\", \"content\": original_prompt}],\n",
        "        timeout = 1200)\n",
        "\n",
        "    ori_answer = completion.choices[0].message.content\n",
        "\n",
        "    total += 1\n",
        "    match = re.search(r'[-+]?\\d*\\.\\d+|\\d+', ori_answer)\n",
        "    if match:\n",
        "        ori_answer = float(match.group())\n",
        "\n",
        "    if float(target) == float(ori_answer):\n",
        "        total_right += 1\n",
        "\n",
        "\n",
        "    overall_with_steps = \"Original question statement: \" + question + '\\n\\n'\n",
        "    for i in range(len(algorithms)):\n",
        "\n",
        "        reformulation_prompt = f\"Please thoroughly reformulate the math question statement based on the following instruction:\\n\\n{steps[i][0]}\\n{steps[i][1]}\\n\\nQuestion statement to reformulate: {overall_with_steps}.\"\n",
        "\n",
        "        completion = client.chat.completions.create(\n",
        "                model = model_id, temperature = 0.0, max_tokens = 768,\n",
        "\n",
        "                messages=[{\"role\": \"system\", \"content\": \"Please reformulate and enrich the math question to be extremely informative and detailed for LLM to interpret better. You are allowed to infer and fill-in unspecified information based on your domain expertise!\"},\n",
        "                            {\"role\": \"user\", \"content\": reformulation_prompt}],\n",
        "                timeout = 1200)\n",
        "\n",
        "        reformulated_history = completion.choices[0].message.content\n",
        "        overall_with_steps += steps[i][0] + '\\n' + steps[i][1] + reformulated_history + '\\n\\n'\n",
        "\n",
        "    ADO_prompt = (\n",
        "        'Given a math question, please solve it by returning the final answer as a number.' +\n",
        "        f'\\n\\nQuestion: {overall_with_steps}' +\n",
        "        \"Output format: directly return an algebric number representing the answer; do NOT explain anything. You MUST follow this format: 'The answer is: 34.5'!!!\"\n",
        "    )\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "        model = model_id, temperature = 0, seed = 0,\n",
        "\n",
        "        messages=[{\"role\": \"system\", \"content\": 'Please solve the math question presented by outputting the final answer.'},\n",
        "                    {\"role\": \"user\", \"content\": ADO_prompt}],\n",
        "        timeout = 1200)\n",
        "\n",
        "    answer = completion.choices[0].message.content\n",
        "\n",
        "    match = re.search(r'[-+]?\\d*\\.\\d+|\\d+', answer)\n",
        "    if match:\n",
        "        answer = float(match.group())\n",
        "\n",
        "    if float(target) == float(answer):\n",
        "        ADO_total_right += 1\n",
        "\n",
        "    print(target, ori_answer, answer)\n",
        "    print(f'Total: {total}, Total Right: {total_right}, ADE Total Right: {ADO_total_right}')\n",
        "    print('----------------------------------------------------------------------------------------')\n",
        "    print()"
      ],
      "metadata": {
        "id": "5GEINyFugDSx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}